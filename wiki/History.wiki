#summary History of the Planarity Project

by John Boyer

= Origin =

Early in my graduate studies (1996), I took a graph algorithms course from Wendy Myrvold, who later became my Ph.D. supervisor.  For my course project, I chose to study linear time planarity algorithms, which were widely regarded as being quite complex.  

The Lempel-Even-Cederbaum (LEC) planarity algorithm is a _vertex addition_ method that was optimized to linear time by the PQ-tree data structure created by Booth and Lueker. In a selected order, each vertex is added to a partial embedding, along with the edges incident to that new vertex and the vertices previously added to the partial embedding. The LEC algorithm relies for its correctness on adding vertices in the order produced by an _st_-numbering.

In an _st_-numbering, the first vertex _s_ is the source, the last vertex _t_ is the target, and every vertex in between has a path of lower numbered vertices leading back to _s_ and a path of higher numbered vertices leading to _t_.  The fact that all vertices have a path of lower numbered vertices back to _s_ means that a single PQ-tree can be used to manage the partial embedding as vertices are added. The fact that all vertices have a path of higher numbered vertices leading to _t_ means that, at each vertex step, the partial embedding can be manipulated so that all vertices with connections to unembedded vertices appear in a single face of the partial embedding.

The PQ-tree has many templates that characterize how to manipulate it, and a number of optimizations for how to detect and apply those template patterns efficiently.  I began to focus on the LEC algorithm over other planarity algorithms because it seemed that it might be possible to make a significant simplification.  I realized that a DFS tree taken from the bottom up had the key property needed for correctness, i.e. that all vertices had a path of ancestors to the root.  Not having a single source seemed only to introduce the need to handle a forest, but some PQ tree templates seemed to be unnecessary and others were simpler.

About a month after the course was over, Wendy contacted me and asked if I was going to pursue my project any further, and if not then could she pursue it independently.  More than once I've said that I didn't need a load of bricks to fall on my head to realize that as a potential thesis topic, this had legs. 

= Edge Addition: A New Planar Embedding Algorithm =

After a few meetings, Wendy and I had worked out the fact that we would work directly on a graph data structure that could manage biconnected components and whose vertices were equipped with extra data to manage planarity information of our algorithm. We defined an externally active vertex as one that had to remain on the external face as the current vertex is embedded, and we defined an internally active vertex as one to which an edge or biconnected component must be attached as part of embedding the current vertex.  We defined a _Walkup_ routine that would figure out how to flip biconnected components and take paths that avoided externally active vertices in order to embed the new vertex, and we defined a routine called _Walkdown_ that would simply use the path and flipping information collected by _Walkup_ to actually perform the vertex embedding.  Then, it was my job to go forth and make a full and complete project of it by sorting out all the details related to formally proving correctness and achieving linear time performance.

For correctness, a straightforward case analysis was possible based on all the possible path selections that could be made by the _Walkup_.  These _Walkup_ path selection rules were eventually published, and although they are simpler than PQ-tree manipulations, it has turned out to be possible to create a fundamentally new planarity algorithm whose implementation and proof of correctness does not rely on them by focusing on the _Walkdown_.  But I'm getting ahead of the story.

For linear time performance, I felt it was best to create an implementation as a way to focus myself on all the details to ensure no aspect of performance considerations were missed.  As I did this, it became clear that the _Walkdown_ could incrementally make decisions about what paths to take and what biconnected components to flip as it embedded the individual edges between the vertex being embedded and its various DFS descendants already embedded.  The only reason for retaining the _Walkup_, it appeared, was to help identify the biconnected components pertinent for the _Walkdown_ to visit in order to embed edges.  

Not only did the new approach give a clear picture of how the partial embedding changed as a particular edge was embedded, but it was even clear how the notions of internal activity and external activity would also dynamically change in response to the addition of a single edge. It was clear that this had become an *edge addition* method. 

Although I had managed to implement this version by mid-1998, I had not yet created a formal proof of correctness.  The corresponding vertex addition method had more complicated path selection rules in the _Walkup_, but the path selection rules resulted from case analysis in a straightforward manner.  It had still to be proven that this new edge addition approach, with it's very simple path selection rules in the _Walkdown_ and its dynamic external and internal activity, was correct based on more sophisticated analysis.  Hence, Wendy and I decided to report our vertex addition method is the SODA paper that appeared in 1999.  Meanwhile, I was to proceed into a Ph.D. program with this new approach to prove it correct and efficient, and to create a full Kuratowski subgraph isolator.

= Planarity-Related Algorithms =

TBD

Outerplanarity

Subgraph Homeomorphism

Drawing

= An Extensible Implementation and Test Framework =

TBD